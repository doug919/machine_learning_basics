"""CS578 - HW2, Fall 2015, Purdue Universitymain function@author I-Ta Lee@date 09/28/2015"""# python libimport sys import osimport argparseimport logging# third-party libimport numpy as np# my libfrom mylib.Features import FeatureSet from mylib import Learners# constantsALGO_PERCEPTRON = 1ALGO_WINNOW = 2ALGO_DUAL_PERCEPTRON = 3# I prefer write these functions in OOP, so they are located at mylib.Learners #def perceptron(maxIterations, featureSet)#    See mylib.Learners.Perceptron.fit()#    pass#def winnow(maxIterations, featureSet):#    See mylib.Learners.Winnow.fit()#    pass#def predict_one(weights, input_snippet):#    See mylib.Learners.Perceptron.predict_one()#    See mylib.Learnners.Winnow.predict_one()#    passdef get_arguments(argv):    parser = argparse.ArgumentParser(description='CS180 HW2 Winnow and Perceptron by I-Ta Lee')    parser.add_argument('training_data', metavar='TRAINING_DATA',                         help='training data in csv format')    parser.add_argument('validating_data', metavar='VALIDATING_DATA',                         help='validation data in csv format')    parser.add_argument('testing_data', metavar='TESTINIG_DATA',                         help='testing data in csv format')    parser.add_argument('-a', '--algorithm', metavar='ALGO', type=int, default=ALGO_PERCEPTRON, choices=range(1, 4),                        help='choose algorithm: 1. perceptron, 2. winnow, 3. dual perceptron (DEFAULT: 1)')    parser.add_argument('-i', '--max_iteration', metavar='MAXITERATION', type=int, default=10,                         help='the maximum number of iterations. should be a positive integer (DEFAULT: 10)')    parser.add_argument('-f', '--feature_select', metavar='FEATURE', type=int, default=FeatureSet.FEATURE_UNIGRAM, choices=range(1, 4),                        help='choose feature set: 1. unigram, 2. bigram 3. both (DEFAULT: 1)')    parser.add_argument('-l', '--learning_rate', metavar='LEARNINGRATE', type=float, default=1.0,                         help='learning rate (DEFAULT: 1.0)')    parser.add_argument('-u', '--unigram_tf_threshold', metavar='THRESHOLD', type=float, default=3,                         help='unigram term frequency threshold for feature selection (DEFAULT: >=3)')    parser.add_argument('-b', '--bigram_tf_threshold', metavar='THRESHOLD', type=float, default=2,                         help='bigram term frequency threshold for feature selection (DEFAULT: >=2)')    parser.add_argument('-g', '--avg_perceptron', action='store_true', default=False,                         help='use averaged perceptron instead of perceptron (-a should be 1)')    parser.add_argument('-w', '--dump_feature', metavar='FILE_NAME', default=None,                        help='dump the selected feature set (DEFAULT: None)')    parser.add_argument('-r', '--load_feature', metavar='FILE_NAME', default=None,                        help='file path for the feature set to read; will ignore the feature selected by -f (DEFAULT: None)')    parser.add_argument('-v', '--verbose', action='store_true', default=False,                         help='show info messages')    parser.add_argument('-d', '--debug', action='store_true', default=False,                         help='show debug messages')    args = parser.parse_args(argv)    return argsif __name__ == '__main__':    # get arguments    args = get_arguments(sys.argv[1:])    # set debug level    if args.debug:        loglevel = logging.DEBUG    elif args.verbose:        loglevel = logging.INFO    else:        loglevel = logging.ERROR    logging.basicConfig(format='[%(levelname)s][%(name)s] %(message)s', level=loglevel)     logger = logging.getLogger(__name__)    logger.info("algorithm=%d, max_iteration=%d, feature_set=%d" % (args.algorithm, args.max_iteration, args.feature_select))    ### feature extraction    feature_set = FeatureSet(loglevel=loglevel)     # if args.load_feature is not None, we will ignore args.feature_set    if args.load_feature is not None:        # load from file        feature_set.load(args.load_feature)    else:        # feature extraction        feature_select = {            1: [FeatureSet.FEATURE_UNIGRAM],            2: [FeatureSet.FEATURE_BIGRAM],            3: [FeatureSet.FEATURE_UNIGRAM, FeatureSet.FEATURE_BIGRAM],        } [args.feature_select]        raw_path = {}        raw_path['train'] = args.training_data        raw_path['validate'] = args.validating_data        raw_path['test'] = args.testing_data        feature_set.extract_feature(raw_path, feature_select,                                     unigram_tf_threshold=args.unigram_tf_threshold,                                     bigram_tf_threshold=args.bigram_tf_threshold)    # dump file if specified    if args.dump_feature is not None:        feature_set.dump(args.dump_feature)    ### learning    # ToDo: improve, not create objects    learner = {        ALGO_PERCEPTRON: Learners.Perceptron(average=args.avg_perceptron),         ALGO_WINNOW: Learners.Winnow(),        ALGO_DUAL_PERCEPTRON: Learners.DualPerceptron()    } [args.algorithm]    if args.algorithm == ALGO_DUAL_PERCEPTRON:  # this takes time        logger.debug("start building kernel")        kernel = Learners.DualPerceptron.linear_kernel(feature_set.X_train)        logger.debug("end building kernel")    else:        kernel = None    for i in range(args.max_iteration):        print 'epoch %d' % i        learner.fit_one_epoch(feature_set.X_train, feature_set.y_train,                               clear=(i == 0),                               alpha=2.0,                              kernel=kernel,                              learning_rate=args.learning_rate)        train_result = learner.score(feature_set.X_train, feature_set.y_train,                                      accuracy=True,                                      precision=True,                                      recall=True,                                      f1=True)        print "training accuracy: %f" % (train_result['accuracy'])        print "training precision: %f" % (train_result['precision'])        print "training recall: %f" % (train_result['recall'])        print "training f1: %f" % (train_result['f1'])        validate_result = learner.score(feature_set.X_validate, feature_set.y_validate,                                         accuracy=True,                                         precision=True,                                         recall=True,                                         f1=True)        print "validating accuracy: %f" % (validate_result['accuracy'])        print "validating precision: %f" % (validate_result['precision'])        print "validating recall: %f" % (validate_result['recall'])        print "validating f1: %f" % (validate_result['f1'])        test_result = learner.score(feature_set.X_test, feature_set.y_test,                                     accuracy=True,                                     precision=True,                                     recall=True,                                     f1=True)        print "testing accuracy: %f" % (test_result['accuracy'])        print "testing precision: %f" % (test_result['precision'])        print "testing recall: %f" % (test_result['recall'])        print "testing f1: %f" % (test_result['f1'])        print '--------------------------------------------------------------'